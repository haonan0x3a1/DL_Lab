{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bcadfbf",
   "metadata": {},
   "source": [
    "# 深度学习实验四:卷积神经网络编程\n",
    "\n",
    "本次实验练习使用torch.nn中的类设计一个卷积神经网络进行MNIST手写体数字图像分类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bed71e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "姓名:王浩南, 学号:E02014154\n"
     ]
    }
   ],
   "source": [
    "name = '王浩南'#填写你的姓名\n",
    "sid = 'E02014154'#填写你的学号\n",
    "\n",
    "print('姓名:%s, 学号:%s'%(name, sid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76965a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195ea40e",
   "metadata": {},
   "source": [
    "# 1. 设计CNN类\n",
    "\n",
    "从torch.nn.Module派生一个子类CNN，表示一个卷积神经网络;\n",
    "\n",
    "请合理设计网络各个层，尝试使用不同的结构，比如skip connection, batch normalization,group convolution等。\n",
    "\n",
    "你的网络模型中至少有2个卷积层、2个聚合层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c4f906a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#在下面添加代码，实现卷积神经网络,用于识别MNIST手写体数字\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # 定义卷积层1，输入通道数为1，输出通道数为16，卷积核大小为3x3\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3)\n",
    "        # 定义批量归一化层1\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=16)\n",
    "        # 定义激活函数\n",
    "        self.act1 = nn.ReLU()\n",
    "        # 定义池化层1，池化核大小为2x2\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # 定义卷积层2，输入通道数为16，输出通道数为32，卷积核大小为3x3\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)\n",
    "        # 定义批量归一化层2\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=32)\n",
    "        # 定义激活函数\n",
    "        self.act2 = nn.ReLU()\n",
    "        # 定义池化层2，池化核大小为2x2\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # 定义跳跃连接\n",
    "        self.residual = nn.Sequential(\n",
    "            # 定义卷积层3，输入通道数为32，输出通道数为32，卷积核大小为3x3\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3),\n",
    "            # 定        nn.BatchNorm2d(num_features=32),\n",
    "            nn.ReLU(),\n",
    "            # 定义卷积层4，输入通道数为32，输出通道数为32，卷积核大小为3x3\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3),\n",
    "            nn.BatchNorm2d(num_features=32)\n",
    "        )\n",
    "    \n",
    "        # 定义全连接层1\n",
    "        self.fc1 = nn.Linear(in_features=8*10*10, out_features=64)\n",
    "        # 定义全连接层2，输入神经元数为64，输出神经元数为10（因为MNIST数据集的输出类别为10个数字）\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 前向传播流程\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        # 跳跃连接的前向传播\n",
    "        residual = self.residual(x)\n",
    "        # 将输入x与跳跃连接的输出相加\n",
    "        x = x + residual\n",
    "        \n",
    "        # 将二维特征图展平成一维向量\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3558860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6576,  0.7030,  0.4242, -0.4281, -0.2002,  0.0815, -0.2710, -1.1152,\n",
      "         -0.3549, -0.2074],\n",
      "        [-0.2827, -0.2302, -0.6050, -0.2631, -0.5165,  0.1290,  0.2236,  0.1697,\n",
      "          0.6842, -0.1549],\n",
      "        [-1.0891, -0.0466, -0.7966, -1.0496,  0.3134,  1.0357, -0.0770,  0.2852,\n",
      "         -0.7086,  0.0168],\n",
      "        [-0.1280,  0.1394,  0.5918, -0.0686, -0.3309,  0.4990, -0.4384, -0.2389,\n",
      "         -0.5588,  0.0492],\n",
      "        [-1.0132, -1.1976, -0.0974, -0.3391,  0.4585,  0.6251,  0.3896,  0.9837,\n",
      "         -0.8852, -0.0971],\n",
      "        [-0.2525, -0.3207,  0.4811, -0.4419, -0.4863,  0.3597,  0.5064, -0.0766,\n",
      "         -0.4492,  0.1345],\n",
      "        [-0.4166, -0.2034,  0.0496, -1.0931, -0.7195, -0.2449,  0.4067, -0.7541,\n",
      "         -0.2105, -0.2866],\n",
      "        [-0.3411, -0.1101, -0.0702, -0.1685,  0.1351,  0.2216, -0.0865,  1.0637,\n",
      "         -0.3842, -0.1962],\n",
      "        [-0.0135,  0.9715, -0.3261, -0.2566, -0.2664,  0.0204,  0.1417, -0.2529,\n",
      "         -0.4762, -0.1795],\n",
      "        [-1.2264,  0.4009,  0.4381, -0.9970, -0.7003,  0.8808, -0.4437,  0.1818,\n",
      "         -1.1527,  0.2485]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#测试MLP类\n",
    "X = torch.rand((10,1,28,28),dtype = torch.float32)\n",
    "net = CNN()\n",
    "Y = net(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c909a712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([10, 10])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape #N*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "498e5542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight : torch.Size([16, 1, 3, 3])\n",
      "conv1.bias : torch.Size([16])\n",
      "bn1.weight : torch.Size([16])\n",
      "bn1.bias : torch.Size([16])\n",
      "conv2.weight : torch.Size([32, 16, 3, 3])\n",
      "conv2.bias : torch.Size([32])\n",
      "bn2.weight : torch.Size([32])\n",
      "bn2.bias : torch.Size([32])\n",
      "residual.0.weight : torch.Size([32, 32, 3, 3])\n",
      "residual.0.bias : torch.Size([32])\n",
      "residual.2.weight : torch.Size([32, 32, 3, 3])\n",
      "residual.2.bias : torch.Size([32])\n",
      "residual.3.weight : torch.Size([32])\n",
      "residual.3.bias : torch.Size([32])\n",
      "fc1.weight : torch.Size([64, 800])\n",
      "fc1.bias : torch.Size([64])\n",
      "fc2.weight : torch.Size([10, 64])\n",
      "fc2.bias : torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "#了解MLP中的参数\n",
    "for name,param in net.named_parameters():\n",
    "    print(name,':',param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "778fdcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act1): ReLU()\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act2): ReLU()\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (residual): Sequential(\n",
      "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (fc1): Linear(in_features=800, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#输出模型\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d783b1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: torchsummary in d:\\anaconda\\envs\\my_torch\\lib\\site-packages (1.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#用torchsummary输出模型结构\n",
    "%pip install -i https://pypi.tuna.tsinghua.edu.cn/simple torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d0287c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 26, 26]             160\n",
      "       BatchNorm2d-2           [-1, 16, 26, 26]              32\n",
      "              ReLU-3           [-1, 16, 26, 26]               0\n",
      "         MaxPool2d-4           [-1, 16, 13, 13]               0\n",
      "            Conv2d-5           [-1, 32, 11, 11]           4,640\n",
      "       BatchNorm2d-6           [-1, 32, 11, 11]              64\n",
      "              ReLU-7           [-1, 32, 11, 11]               0\n",
      "         MaxPool2d-8             [-1, 32, 5, 5]               0\n",
      "            Conv2d-9             [-1, 32, 3, 3]           9,248\n",
      "             ReLU-10             [-1, 32, 3, 3]               0\n",
      "           Conv2d-11             [-1, 32, 1, 1]           9,248\n",
      "      BatchNorm2d-12             [-1, 32, 1, 1]              64\n",
      "           Linear-13                   [-1, 64]          51,264\n",
      "           Linear-14                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 75,370\n",
      "Trainable params: 75,370\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.37\n",
      "Params size (MB): 0.29\n",
      "Estimated Total Size (MB): 0.66\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(net.cuda(), input_size = (1,28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05a0a95",
   "metadata": {},
   "source": [
    "# 2.训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd2652a",
   "metadata": {},
   "source": [
    "# 2.1 第一步，对数据做预处理\n",
    "\n",
    "MNIST图像的像素取值范围是[0,1]，先把值域改变为[-1,1]. 在PyTorch中，可以使用torchvision.transforms.Normalize类处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35bf287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets,transforms\n",
    "\n",
    "#构造一个变换，将像素值范围变换到[-1,1]\n",
    "normalizer =  transforms.Normalize((0.5,), (0.5,))#一行代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8858901d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义一个变换序列transform，包含两个变换：第一个将PIL图像转换为张量，第二个是normalizer\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), normalizer])#一行代码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b760c9",
   "metadata": {},
   "source": [
    "# 2.2 第二步，构造训练集，加入预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdfffe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/'\n",
    "mnist_train = datasets.MNIST(data_path,download=False,train = True,transform = transform)\n",
    "mnist_test =  datasets.MNIST(data_path,download=False,train = False,transform = transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bc299c",
   "metadata": {},
   "source": [
    "# 2.3 第三步，构造加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc2be185",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #可以自己定义batch_size大小\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f1972b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#从加载器里获取一批样本，并输出样本张量的形状\n",
    "imgs,labels = next(iter(train_loader))#一行样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33a9ab9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([32, 1, 28, 28])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0ee945c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([32])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83cab93",
   "metadata": {},
   "source": [
    "# 2.4 第四步，训练模型\n",
    "\n",
    "注意：训练卷积神经网络时，网络的输入是四维张量，尺寸为$N\\times C \\times H \\times W$，分别表示张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d2d6f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(model, loader, epochs, lr = 0.1):\n",
    "    epsilon = 1e-6\n",
    "    \n",
    "    #将model置于train模式\n",
    "    #一行代码\n",
    "    net.train()\n",
    "    \n",
    "    #定义合适的优化器\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)#一行代码\n",
    "    \n",
    "    #定义损失函数\n",
    "    loss = F.cross_entropy#一行代码\n",
    "    \n",
    "    #请在下面完成训练代码\n",
    "    #请在迭代过程中每100次迭代，输出一次损失\n",
    "    loss0 = 0\n",
    "    for epoch in range(epochs):\n",
    "        for it,(imgs, labels) in enumerate(loader):\n",
    "            #1. zero_grads\n",
    "            #请用一行代码实现\n",
    "            optimizer.zero_grad()\n",
    "            imgs, labels = imgs.cuda(), labels.cuda()\n",
    "\n",
    "            #2. F.P.前向传播\n",
    "            #请用一行代码实现\n",
    "            logits = model(imgs)\n",
    "\n",
    "            #3. 计算损失            \n",
    "            loss1 = loss(logits, labels)#请用一行代码实现\n",
    "            \n",
    "            if(abs(loss1.item() - loss0)<epsilon):\n",
    "                break\n",
    "                \n",
    "            loss0 = loss1.item()\n",
    "                \n",
    "            if it%100==0:\n",
    "                print('epoch %d, iter %d, loss = %f\\n'%(epoch,it,loss1.item()))\n",
    "                \n",
    "            #4. 后向传播\n",
    "            #请用一行代码实现\n",
    "            loss1.backward()\n",
    "            \n",
    "            #5. 梯度下降\n",
    "            #请用一行代码实现.\n",
    "            optimizer.step()    \n",
    "    return model            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "309b7f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, iter 0, loss = 2.440039\n",
      "\n",
      "epoch 0, iter 100, loss = 0.197161\n",
      "\n",
      "epoch 0, iter 200, loss = 0.234046\n",
      "\n",
      "epoch 0, iter 300, loss = 0.064733\n",
      "\n",
      "epoch 1, iter 0, loss = 0.092887\n",
      "\n",
      "epoch 1, iter 100, loss = 0.067598\n",
      "\n",
      "epoch 1, iter 200, loss = 0.121505\n",
      "\n",
      "epoch 1, iter 300, loss = 0.026409\n",
      "\n",
      "epoch 2, iter 0, loss = 0.028156\n",
      "\n",
      "epoch 2, iter 100, loss = 0.040637\n",
      "\n",
      "epoch 2, iter 200, loss = 0.080713\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [18], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m model \u001B[38;5;241m=\u001B[39m CNN()\n\u001B[0;32m      4\u001B[0m model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mcuda()\n\u001B[1;32m----> 5\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mTrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn [17], line 31\u001B[0m, in \u001B[0;36mTrain\u001B[1;34m(model, loader, epochs, lr)\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;66;03m#3. 计算损失            \u001B[39;00m\n\u001B[0;32m     29\u001B[0m loss1 \u001B[38;5;241m=\u001B[39m loss(logits, labels)\u001B[38;5;66;03m#请用一行代码实现\u001B[39;00m\n\u001B[1;32m---> 31\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m(\u001B[38;5;28mabs\u001B[39m(\u001B[43mloss1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m-\u001B[39m loss0)\u001B[38;5;241m<\u001B[39mepsilon):\n\u001B[0;32m     32\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m     34\u001B[0m loss0 \u001B[38;5;241m=\u001B[39m loss1\u001B[38;5;241m.\u001B[39mitem()\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#训练模型\n",
    "\n",
    "model = CNN()\n",
    "model = model.cuda()\n",
    "model = Train(model, test_loader, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c952715b",
   "metadata": {},
   "source": [
    "# 2.5 第五步，测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd24d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#编写模型测试过程\n",
    "def Evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    counts = 0\n",
    "    for imgs, labels in loader:\n",
    "        imgs, labels = imgs.cuda(), labels.cuda()\n",
    "        logits = model(imgs)\n",
    "        yhat = logits.argmax(dim = 1)\n",
    "        correct = correct + (yhat==labels).sum().item()\n",
    "        counts = counts + imgs.size(0)\n",
    "    \n",
    "    accuracy = correct / counts\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a5d299",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = Evaluate(model,test_loader)\n",
    "print('Accuracy = %0.3f'%(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d12f859",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs,labels  = next(iter(test_loader))\n",
    "imgs, labels = imgs.cuda(), labels.cuda()\n",
    "\n",
    "logits = model(imgs)\n",
    "\n",
    "imgs, labels = imgs.cpu(), labels.cpu()\n",
    "\n",
    "yhat = logits.argmax(dim = 1)\n",
    "\n",
    "plt.figure(figsize = (16,10))\n",
    "for i in range(imgs.size(0)):\n",
    "    plt.subplot(4,8,i+1)\n",
    "    plt.imshow(imgs[i].squeeze()/2+0.5,cmap = 'gray')\n",
    "    plt.axis('off')\n",
    "    plt.title('GT=%d, Pred = %d'%(labels[i],yhat[i]))\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My_Torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov  4 2022, 16:35:55) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "3bb1b9170a30f8b8b3f43303ab1db72cc75c30a263a3ca258880608906b0fbee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
